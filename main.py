import torch
import pickle

import causalities


if __name__ == "__main__":
    encoder_dict = {
        "flow_temporal_encoder": {
            "attention_layers": 3,
            "attention_heads": 3,
            "attention_dim": 6,
            "attention_feedforward_dim": 2,
            "dropout": 0.0,
            "masked_time_series": None,
        },
    }

    model_parameters = {
        "flow_series_embedding_dim": 2,
        "flow_input_encoder_layers": 2,
        "bagging_size": None,
        "input_encoding_normalization": True,
        "data_normalization": "none",
        "loss_normalization": "both",
        "positional_encoding": {
            "dropout": 0.1,
        },
        **encoder_dict,
        "copula_decoder": {
            # flow_input_dim and copula_input_dim are passed by the TACTIS module dynamically
            "min_u": 0.05,
            "max_u": 0.95,
            "dsf_marginal": {
                "mlp_layers": 2,
                "mlp_dim": 6,
                "flow_layers": 2,
                "flow_hid_dim": 8,
            },
        },
    }

    for _ in range(10):
        num_samples = 2000
        time_steps = 4
        num_series = 3
        x = torch.randn(num_samples, 1, time_steps)
        y = (torch.randn(num_samples, 1, time_steps) * 10) + 10
        z = x + y
        z0 = torch.randn(num_samples, 1, 1)
        z = torch.cat([z0, z], dim=2)
        z = z[:, :, :-1]
        input_tokens = torch.cat([x, y, z], dim=1)
        with open("simple_data.pkl", "wb") as f:
            pickle.dump(input_tokens, f)

        if torch.cuda.is_available():
            device = torch.device("cuda")
        else:
            device = torch.device("cpu")

        with open("simple_data.pkl", "rb") as f:
            input_tokens = pickle.load(f)
        input_tokens = input_tokens.to(device)

        true_causality_graph = torch.stack(causalities.generate_causalities(input_tokens, "retrain", model_parameters))
        print("causality graph generated by the grand true method:")
        print(true_causality_graph)

        causality_graph = torch.stack(causalities.generate_causalities(input_tokens, "constant series", model_parameters))
        print("causality graph generated by the constant series method:")
        print(causality_graph)

        print("/////////////////////////////////////")
